# applied-machine-learning-project
Clustering, regression, and classification project using Python. Includes EDA, machine learning models, hyperparameter tuning, and explainability techniques like SHAP.

Applied Machine Learning Project: Clustering, Regression, and Classification

Introduction
This repository contains my project for the Applied Machine Learning course. The project demonstrates the application of machine learning techniques in three core areas: Clustering, Regression, and Classification. Using Python, I processed datasets, explored key insights, and implemented various machine learning models, supported by visualizations, metrics, and explainability methods.

Project Details
1. Clustering: Market Segmentation
Dataset: Wholesale Customers Dataset
Objective: Segment wholesale distributor clients based on annual spending in product categories like milk, grocery, and region.
Approach:
Conducted Exploratory Data Analysis (EDA) to understand spending patterns.
Pre-processed the dataset, handling missing values and standardizing features.
Applied clustering algorithms, including k-means and hierarchical clustering.
Evaluated clusters using metrics like silhouette score and the elbow method.
Visualized the clusters using PCA and interpreted results.
2. Regression: Predicting House Prices
Dataset: House Sales Dataset from Kaggle
Objective: Predict house prices based on 79 features describing residential properties in Ames, Iowa.
Approach:
Pre-processed the data:
Imputed missing values.
Encoded categorical variables.
Scaled numerical features.
Implemented and compared regression models:
Linear Regression, Polynomial Regression, Lasso, Ridge.
Experimented with advanced techniques like Decision Tree Regressor and Random Forest Regressor.
Tuned hyperparameters for optimal model performance.
Evaluated models using metrics such as Root Mean Square Error (RMSE) and compared them in a consolidated table.
3. Classification: Predicting Annual Income
Dataset: UCI Adult Dataset
Objective: Predict whether an individual earns more or less than $50K per year based on demographic and employment data.
Approach:
Conducted EDA to analyze data distribution and correlations.
Pre-processed the data by handling missing values and encoding categorical features.
Implemented multiple classification models:
K-Nearest Neighbors (KNN), Random Forest, Support Vector Machines (SVM).
Experimented with additional models: XGBoost, Logistic Regression, and Voting Ensemble.
Tuned hyperparameters using GridSearchCV for improved performance.
Evaluated model performance using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.
Incorporated explainability techniques like SHAP and LIME to understand model decisions.[README.md](https://github.com/user-attachments/files/17966167/README.md)
 LIME
